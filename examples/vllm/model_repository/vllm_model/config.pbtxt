name: "vllm_model"
backend: "vllm"
max_batch_size: 8
input [
  { name: "text_input" data_type: TYPE_STRING dims: [ 1 ] }
]
output [
  { name: "text_output" data_type: TYPE_STRING dims: [ 1 ] }
]
parameters: { key: "model" value: { string_value: "meta-llama/Llama-3.1-8B-Instruct" } }
