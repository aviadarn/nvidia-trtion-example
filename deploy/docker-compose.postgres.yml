services:
  triton:
    image: nvcr.io/nvidia/tritonserver:24.10-py3
    command: ["tritonserver", "--model-repository=/models"]
    ports: ["8000:8000", "8001:8001", "8002:8002"]
    volumes:
      - ../examples/python_backend/model_repository:/models
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
  postgres:
    image: postgres:16
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
      POSTGRES_DB: triton
    ports: ["5432:5432"]
  client:
    build:
      context: ..
      dockerfile: shared/clients/Dockerfile
    depends_on: [triton, postgres]
    environment:
      POSTGRES_DSN: postgresql://postgres:postgres@postgres:5432/triton
    command: >
      sh -c 'python triton_infer.py --url triton:8000 --model ensemble_python --text "postgres flow" > /tmp/payload.json &&
             PAYLOAD_JSON="$$(cat /tmp/payload.json)" python postgres_writer.py'
